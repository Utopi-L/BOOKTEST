**Differences Among int, long, long long, and short:**

- **int:**  
  Typically represents a 32-bit integer on most modern systems, but its size can vary based on the compiler and platform.

- **short:**  
  Usually a 16-bit integer, offering a smaller range than int.

- **long:**  
  Its size is platform-dependent. On Windows, it's usually 32-bit, while on some Unix-like systems it can be 64-bit.

- **long long:**  
  Guaranteed to be at least 64 bits. It’s used when a larger range is needed than what int or long can offer.

**Differences Between Unsigned and Signed Types:**

- **Signed Types:**  
  Can represent both negative and positive numbers. Their range is split between negative and positive values.

- **Unsigned Types:**  
  Only represent non-negative values. Because they don’t need to account for negative numbers, they have a range that goes from 0 up to a higher positive value compared to their signed counterpart.

**Differences Between float and double:**

- **float:**  
  Typically a 32-bit floating-point number, offering around 7 decimal digits of precision.

- **double:**  
  Typically a 64-bit floating-point number, offering about 15 decimal digits of precision, making it more suitable for calculations requiring higher accuracy.